# 入服与退服实例<a name="admin_guide_000040"></a>

## 操作场景<a name="s8f2c2e4ee54d4d929e0f420df2a78b8e"></a>

部分角色实例以分布式并行工作的方式对外部业务提供服务，服务会单独保存每个实例是否可以使用的信息，所以需要使用FusionInsight Manager为这些实例执行入服或退服的操作，变更实例的业务可用状态方式。

不支持该此功能的实例，默认无法执行任务。

>![](public_sys-resources/icon-note.gif) **说明：** 
>当前支持退服和入服操作的角色有：HDFS的DataNode、Yarn的NodeManager、HBase的RegionServer。
>-   当DataNode数量少于或等于HDFS的副本数时，不能执行退服操作。若HDFS副本数为3时，则系统中少于4个DataNode，将无法执行退服，Manager在执行退服操作时会等待30分钟后报错并退出执行。
>-   由于Mapreduce任务执行时，会生成一些副本数为10的文件，此时若DataNode实例数少于10时，将无法进行退服操作。
>-   如果退服前，DataNode节点的机架数（机架数由各DataNode节点所配置的“机架”的名称数量决定）大于1；而退服部分DataNode后，剩余的DataNode节点的机架数变为1，则此次退服将会失败。所以需要在退服前评估退服操作对机架数的影响，以调整退服的DataNode节点。
>-   在退服多个DataNode时，如果每个DataNode存储的数据量较大，如果执行选择多个DataNode同时退服，则很有可能会因超时而退服失败。为了避免这种情况，建议每次退服仅退服1个DataNode，进行多次退服操作。

## 操作步骤<a name="section114941822101815"></a>

1.  DataNode节点退服前需要进行健康检查，步骤如下：
    1.  使用客户端用户登录客户端安装节点，并切换到客户端安装目录。
    2.  如果是安全集群，需要使用**hdfs**用户进行权限认证。

        ```
        source bigdata_env               #配置客户端环境变量 
        kinit hdfs                       #设置kinit认证 
        Password for hdfs@HADOOP.COM:    #输入hdfs用户登录密码 
        ```

    3.  执行**hdfs fsck / -list-corruptfileblocks**，检查返回结果。
        -   如果结果是“...has 0 CORRUPT files”，执行[2](#zh-cn_topic_0046737055_step_2)。
        -   如果结果不是“...has 0 CORRUPT files”，并返回损坏的文件名称，执行[1.d](#zh-cn_topic_0046737055_step_1e)。

    4.  <a name="zh-cn_topic_0046737055_step_1e"></a>执行**hdfs dfs -rm **_损坏的文件名称_，删除损坏的文件。

        >![](public_sys-resources/icon-note.gif) **说明：** 
        >删除文件为高危操作，在执行操作前请务必确认对应文件是否不再需要。


2.  <a name="zh-cn_topic_0046737055_step_2"></a>登录FusionInsight Manager。
3.  选择“集群 \>  _待操作集群的名称_  \> 服务”。
4.  单击服务视图中指定的服务名称，并选择“实例“页签。
5.  勾选指定的待退服角色实例。
6.  在“更多”选择“退服”或“入服”。

    输入当前登录的用户密码确认身份，单击“确定”。

    勾选“我确定退服这些实例，并接受服务性能下降的结果。“，单击“确定“，执行相应的操作。

    >![](public_sys-resources/icon-note.gif) **说明：** 
    >实例退服操作未完成时在其他浏览器或窗口重启集群中实例对应的服务，FusionInsight Manager将提示停止退服，实例的“操作状态”显示为“启动”。实际上后台已将该实例退服，请重新执行退服操作同步状态。


