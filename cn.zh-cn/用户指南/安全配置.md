# 安全配置<a name="ZH-CN_TOPIC_0176678780"></a>

Flink主要完成如下安全特性：

-   Flink集群中，各部件支持认证。

    Flink集群内部部件和外部部件之间，支持Kerberos认证。

-   Flink集群中，各部件支持SSL加密传输。
-   Flink集群内部各部件之间，如Flink client和JobManager、JobManager和TaskManager、TaskManager和TaskManager之间支持SSL加密传输。
-   Flink web安全加固。
    -   支持白名单过滤，Flink web只能通过YARN代理访问。
    -   安全头域增强。

-   Flink集群中，各部件的监听端口支持范围可配置。
-   在HA模式下，支持ACL控制。

## 配置对接Kafka<a name="section1211073013347"></a>

Flink样例工程的数据存储在Kafka组件中。向Kafka组件发送数据（需要有Kafka权限用户），并从Kafka组件接收数据。

1.  确保集群安装完成，包括HDFS、Yarn、Flink和Kafka。
2.  创建Topic。
    -   用户使用Linux命令行创建topic，执行命令前需要使用kinit命令进行人机认证，如**_kinit flinkuser_**。

        >![](public_sys-resources/icon-note.gif) **说明：**   
        >flinkuser需要用户自己创建，并拥有创建Kafka的topic权限。具体操作请参考[准备开发用户](https://support.huaweicloud.com/devg-mrs/mrs_06_0389.html)章节。  

        创建topic的命令格式：\{zkQuorum\}表示ZooKeeper集群信息，格式为IP:port。\{Topic\}表示Topic名称。

        **_bin/kafka-topics.sh --create --zookeeper \{zkQuorum\}/kafka --replication-factor 1 --partitions 5 --topic \{Topic\}_**

        例如此处以topic1的数据为例：

        ```
        /opt/client/Kafka/kafka/bin/kafka-topics.sh --create --zookeeper 10.96.101.32:2181,10.96.101.251:24002,10.96.101.177:24002,10.91.8.160:24002/kafka --replication-factor 1 --partitions 5 --topic topic1
        ```

    -   服务端topic权限配置。

        登录集群详情页面，选择“组件管理 \> Kafka \> 服务配置”,参数类别设置为“全部配置”，将Kafka的Broker配置参数“allow.everyone.if.no.acl.found”的值修改为“true”。

3.  安全认证。
    -   **Kerberos认证配置**
        -   客户端配置。

            在Flink配置文件“flink-conf.yaml”中，增加kerberos认证相关配置（主要在“contexts”项中增加“KafkaClient”），示例如下：

            ```
            security.kerberos.login.keytab: /home/demo/flink/release/keytab/flinkuser.keytab
            security.kerberos.login.principal: flinkuser
            security.kerberos.login.contexts: Client,KafkaClient
            security.kerberos.login.use-ticket-cache: false
            ```

        -   运行参数。

            关于“SASL\_PLAINTEXT”协议的运行参数示例如下：

            ```
            --topic topic1 --bootstrap.servers 10.96.101.32:21007 --security.protocol SASL_PLAINTEXT  --sasl.kerberos.service.name kafka //10.96.101.32:21007表示kafka服务器的IP:port
            ```




