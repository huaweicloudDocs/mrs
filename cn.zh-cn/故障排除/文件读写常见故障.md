# 文件读写常见故障<a name="mrs_03_0079"></a>

## 问题背景与现象<a name="zh-cn_topic_0167275826_section33007524175951"></a>

当用户在HDFS上执行写操作时，出现“Failed to place enough replicas:expected…”信息。

## 原因分析<a name="zh-cn_topic_0167275826_section321702661814"></a>

-   DataNode的数据接受器不可用。

    此时DataNode会有如下日志：

    ```
    2016-03-17 18:51:44,721 | WARN | org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5386659f | hadoopc1h2:25009:DataXceiverServer: | DataXceiverServer.java:158
    java.io.IOException: Xceiver count 4097 exceeds the limit of concurrent xcievers: 4096
    at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:140)
    at java.lang.Thread.run(Thread.java:745) 
    ```

-   DataNode的磁盘空间不足。
-   DataNode的心跳有延迟。

## 解决办法<a name="zh-cn_topic_0167275826_section6627991418139"></a>

-   如果DataNode的数据接收器不可用，通过在Manager页面，增加HDFS参数“dfs.datanode.max.transfer.threads”的值解决。
-   如果没有足够的硬盘空间或者CPU，试着增加新的数据节点或确保资源是可用的（磁盘空间或CPU）。
-   如果网络问题，确保网络是可用的。

