# 使用Spark<a name="ZH-CN_TOPIC_0168546833"></a>

-   **[Spark应用下修改split值时报错](Spark应用下修改split值时报错.md)**  

-   **[使用Spark时报错](使用Spark时报错.md)**  

-   **[磁盘容量不足，导致Spark、Hive和Yarn服务不可用](磁盘容量不足-导致Spark-Hive和Yarn服务不可用.md)**  

-   **[引入jar包不正确，导致Spark任务无法运行](引入jar包不正确-导致Spark任务无法运行.md)**  

-   **[Spark任务由于内存不够，作业卡住](Spark任务由于内存不够-作业卡住.md)**  

-   **[运行Spark报错](运行Spark报错.md)**  

-   **[Driver端提示executor memory超限](Driver端提示executor-memory超限.md)**  

-   **[Yarn-cluster模式下，Can't get the Kerberos realm异常](Yarn-cluster模式下-Can-t-get-the-Kerberos-realm异常.md)**  

-   **[JDK版本不匹配启动spark-sql，spark-shell失败](JDK版本不匹配启动spark-sql-spark-shell失败.md)**  

-   **[Yarn-client模式提交ApplicationMaster尝试启动两次失败](Yarn-client模式提交ApplicationMaster尝试启动两次失败.md)**  

-   **[提交Spark任务时，连接ResourceManager异常](提交Spark任务时-连接ResourceManager异常.md)**  

-   **[DaYu调度spark作业失败](DaYu调度spark作业失败.md)**  


